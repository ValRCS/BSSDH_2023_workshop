{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building embeddings from our corpus\n",
    "\n",
    "Now we have our corpus, we can build our embeddings.\n",
    "\n",
    "There are different types of embeddings. At our corpus we will work with word embeddings. However we could think of sentence embeddings, paragraph embeddings, document embeddings, even character or subword embeddings.\n",
    "\n",
    "Word embeddings are vector representations of words. They are useful for many NLP tasks, such as sentiment analysis, text classification, and machine translation. They are also useful for visualising the relationships between words. For example, we can use them to find words with similar meanings, or to find words that are often used together.\n",
    "\n",
    "## Why do we need embeddings?\n",
    "\n",
    "Computers and most machine learnign algorithms in particular work better with numerical data. However, words are not numbers. So we need to find a way to represent words as numbers.\n",
    "\n",
    "Large Language Models such as ChatGPT also use word embeddings to represent words. However, they are trained on huge amounts of data, and so are not always suitable for smaller projects. In this notebook, we will build our own word embeddings from our corpus.\n",
    "\n",
    "## Different types of embedddings\n",
    "\n",
    "There are different types of word embeddings as well, such as:\n",
    "\n",
    "- Word2Vec\n",
    "- GloVe\n",
    "- FastText\n",
    "- BERT\n",
    "\n",
    " We will  also use the gensim library to do this. Gensim is a library for topic modelling, document indexing and similarity retrieval with large corpora. It uses the word2vec algorithm to create vector representations of words, which can then be used to find words with similar meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ver: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "Pandas ver: 2.0.3\n",
      "Gensim ver: 4.3.1\n",
      "Scikit learn ver: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# We will be using the same dataset as in the previous notebook\n",
    "# usual standard imports\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "#python version\n",
    "import sys\n",
    "print(\"Python ver:\", sys.version)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# print version\n",
    "print(\"Pandas ver:\", pd.__version__)\n",
    "\n",
    "# we will need gensim for word2vec embeddings\n",
    "import gensim\n",
    "# print version\n",
    "print(\"Gensim ver:\", gensim.__version__)\n",
    "\n",
    "# we will need scikit learn for tfidf embeddings\n",
    "import sklearn\n",
    "# print version\n",
    "print(\"Scikit learn ver:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from Parquet Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (1637, 9)\n"
     ]
    }
   ],
   "source": [
    "# now let's load parquet file directly from url\n",
    "url = \"https://github.com/ValRCS/BSSDH_2023_workshop/raw/main/data/old_bailey_sample_1720_1913_cleaned.parquet\"\n",
    "df = pd.read_parquet(url)\n",
    "print(\"Dataframe shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: 5686694\n"
     ]
    }
   ],
   "source": [
    "# how much memory does this dataframe use?\n",
    "print(\"Dataframe size:\", df.memory_usage(deep=True).sum())\n",
    "# supposedly Pandas 2.0 has better memory management for strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1637 entries, 1720 to 1913\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   trial_number        1637 non-null   int64 \n",
      " 1   punishment          1162 non-null   object\n",
      " 2   text                1637 non-null   object\n",
      " 3   dirty_len           1637 non-null   int64 \n",
      " 4   clean_len           1637 non-null   int64 \n",
      " 5   words               1637 non-null   object\n",
      " 6   word_count          1637 non-null   int64 \n",
      " 7   word_count_cleaned  1637 non-null   int64 \n",
      " 8   words_lemmatized    1637 non-null   object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 127.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# let's get some statistics about our dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1637.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.329872</td>\n",
       "      <td>3227.827734</td>\n",
       "      <td>3091.967013</td>\n",
       "      <td>608.543677</td>\n",
       "      <td>257.531460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.327506</td>\n",
       "      <td>7288.101079</td>\n",
       "      <td>7020.877032</td>\n",
       "      <td>1376.101195</td>\n",
       "      <td>544.264694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>1291.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>3299.000000</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>161044.000000</td>\n",
       "      <td>156144.000000</td>\n",
       "      <td>29928.000000</td>\n",
       "      <td>11270.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trial_number      dirty_len      clean_len    word_count  \\\n",
       "count   1637.000000    1637.000000    1637.000000   1637.000000   \n",
       "mean      49.329872    3227.827734    3091.967013    608.543677   \n",
       "std       34.327506    7288.101079    7020.877032   1376.101195   \n",
       "min        1.000000      57.000000      51.000000     10.000000   \n",
       "25%       22.000000     302.000000     285.000000     50.000000   \n",
       "50%       44.000000    1359.000000    1291.000000    245.000000   \n",
       "75%       70.000000    3453.000000    3299.000000    654.000000   \n",
       "max      173.000000  161044.000000  156144.000000  29928.000000   \n",
       "\n",
       "       word_count_cleaned  \n",
       "count         1637.000000  \n",
       "mean           257.531460  \n",
       "std            544.264694  \n",
       "min              6.000000  \n",
       "25%             31.000000  \n",
       "50%            115.000000  \n",
       "75%            277.000000  \n",
       "max          11270.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can get basic statistics about our dataframe\n",
    "df.describe() # for numerical columns - returns a dataframe as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>punishment</th>\n",
       "      <th>text</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>words_lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>37</td>\n",
       "      <td>Eighteen Months' Hard Labour.</td>\n",
       "      <td>95 john leigh 40 unlawfully obtaining from wal...</td>\n",
       "      <td>18027</td>\n",
       "      <td>17288</td>\n",
       "      <td>[95, john, leigh, 40, unlawfully, obtaining, w...</td>\n",
       "      <td>3237</td>\n",
       "      <td>1466</td>\n",
       "      <td>[95, john, leigh, 40, unlawfully, obtain, walt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>71</td>\n",
       "      <td>Confined Three Months</td>\n",
       "      <td>368 john johnson was indicted for stealing on ...</td>\n",
       "      <td>192</td>\n",
       "      <td>179</td>\n",
       "      <td>[368, john, johnson, indicted, stealing, 9th, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>[368, john, johnson, indict, steal, 9th, decem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>107 m eleanor coshee otherwise southwall late ...</td>\n",
       "      <td>3708</td>\n",
       "      <td>3544</td>\n",
       "      <td>[107, m, eleanor, coshee, southwall, late, par...</td>\n",
       "      <td>704</td>\n",
       "      <td>312</td>\n",
       "      <td>[107, m, eleanor, coshee, southwall, late, par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>2</td>\n",
       "      <td>DEATH</td>\n",
       "      <td>186 josiah allen was indicted for burglariousl...</td>\n",
       "      <td>3395</td>\n",
       "      <td>3260</td>\n",
       "      <td>[186, josiah, allen, indicted, burglariously, ...</td>\n",
       "      <td>655</td>\n",
       "      <td>275</td>\n",
       "      <td>[186, josiah, allen, indict, burglariously, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>49</td>\n",
       "      <td>[Transportation. See summary.]</td>\n",
       "      <td>william simpson of st jamess clerkenwell was i...</td>\n",
       "      <td>3557</td>\n",
       "      <td>3428</td>\n",
       "      <td>[william, simpson, st, jamess, clerkenwell, in...</td>\n",
       "      <td>667</td>\n",
       "      <td>261</td>\n",
       "      <td>[william, simpson, st, jamess, clerkenwell, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trial_number                      punishment  \\\n",
       "year                                                 \n",
       "1896            37   Eighteen Months' Hard Labour.   \n",
       "1841            71           Confined Three Months   \n",
       "1762            19                            None   \n",
       "1835             2                           DEATH   \n",
       "1731            49  [Transportation. See summary.]   \n",
       "\n",
       "                                                   text  dirty_len  clean_len  \\\n",
       "year                                                                            \n",
       "1896  95 john leigh 40 unlawfully obtaining from wal...      18027      17288   \n",
       "1841  368 john johnson was indicted for stealing on ...        192        179   \n",
       "1762  107 m eleanor coshee otherwise southwall late ...       3708       3544   \n",
       "1835  186 josiah allen was indicted for burglariousl...       3395       3260   \n",
       "1731  william simpson of st jamess clerkenwell was i...       3557       3428   \n",
       "\n",
       "                                                  words  word_count  \\\n",
       "year                                                                  \n",
       "1896  [95, john, leigh, 40, unlawfully, obtaining, w...        3237   \n",
       "1841  [368, john, johnson, indicted, stealing, 9th, ...          34   \n",
       "1762  [107, m, eleanor, coshee, southwall, late, par...         704   \n",
       "1835  [186, josiah, allen, indicted, burglariously, ...         655   \n",
       "1731  [william, simpson, st, jamess, clerkenwell, in...         667   \n",
       "\n",
       "      word_count_cleaned                                   words_lemmatized  \n",
       "year                                                                         \n",
       "1896                1466  [95, john, leigh, 40, unlawfully, obtain, walt...  \n",
       "1841                  23  [368, john, johnson, indict, steal, 9th, decem...  \n",
       "1762                 312  [107, m, eleanor, coshee, southwall, late, par...  \n",
       "1835                 275  [186, josiah, allen, indict, burglariously, br...  \n",
       "1731                 261  [william, simpson, st, jamess, clerkenwell, in...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random sample of 5 rows\n",
    "# let's set seed first\n",
    "import numpy as np\n",
    "np.random.seed(2023) # so we will get the same results\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we might want to plot histogram of word_count_cleaned\n",
    "# this will give us a more detailed view of the distribution of word counts\n",
    "df.word_count_cleaned.hist() # this will plot histogram of word counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>punishment</th>\n",
       "      <th>text</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>words_lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1</td>\n",
       "      <td>DEATH</td>\n",
       "      <td>117 john selby watson 67 was indicted for the ...</td>\n",
       "      <td>161044</td>\n",
       "      <td>156144</td>\n",
       "      <td>[117, john, selby, watson, 67, indicted, wilfu...</td>\n",
       "      <td>29928</td>\n",
       "      <td>11270</td>\n",
       "      <td>[117, john, selby, watson, 67, indict, wilful,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trial_number punishment  \\\n",
       "year                            \n",
       "1872             1      DEATH   \n",
       "\n",
       "                                                   text  dirty_len  clean_len  \\\n",
       "year                                                                            \n",
       "1872  117 john selby watson 67 was indicted for the ...     161044     156144   \n",
       "\n",
       "                                                  words  word_count  \\\n",
       "year                                                                  \n",
       "1872  [117, john, selby, watson, 67, indicted, wilfu...       29928   \n",
       "\n",
       "      word_count_cleaned                                   words_lemmatized  \n",
       "year                                                                         \n",
       "1872               11270  [117, john, selby, watson, 67, indict, wilful,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like we have some outliers, let's see what they are\n",
    "df[df.word_count_cleaned > 10000]\n",
    "# looks like there was a very long trial that ended up badly for the defendant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for our histogram we will skip this outlier\n",
    "df[df.word_count_cleaned < 10000].word_count_cleaned.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we are still not getting a good view of the distribution\n",
    "# let's increase the number of bins\n",
    "df[df.word_count_cleaned < 10000].word_count_cleaned.hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# again we can see that most of the documents are short\n",
    "# certainly Justice in England was swift and brutal\n",
    "\n",
    "# let's see distribution among shorter documents of less than 1000 words\n",
    "df[df.word_count_cleaned < 1000].word_count_cleaned.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concerns on short texts\n",
    "\n",
    "Short texts might not have enough information to build good embeddings. However, we will try to build them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am concerned that we will not get very useful embeddings from the very short documents but for now we will leave them in\n",
    "\n",
    "# Also I noticed that our cleaning still left numerical digits in the text\n",
    "# sometimes they are important, but in general we can remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words removed with digits only: 12700\n",
      "Total words remaining: 408879\n"
     ]
    }
   ],
   "source": [
    "# let's remove digits from our words_lemmatized column that contains list of wordsd\n",
    "# let's build a function that will remove any digits in from a list of words\n",
    "def remove_digits(words):\n",
    "    \"\"\"Removes digits from a list of words\"\"\"\n",
    "    return [word for word in words if not word.isdigit()]\n",
    "# let's apply it to our dataframe\n",
    "df.words_lemmatized = df.words_lemmatized.apply(remove_digits)\n",
    "# let's make a column with word count after removing digits\n",
    "df[\"word_count_cleaned_no_digits\"] = df.words_lemmatized.apply(len)\n",
    "# let's see how many documents we have now\n",
    "df.shape\n",
    "# how many words did we remove?\n",
    "print(\"Words removed with digits only:\", df.word_count_cleaned.sum() - df.word_count_cleaned_no_digits.sum())\n",
    "# total words remaining\n",
    "print(\"Total words remaining:\", df.word_count_cleaned_no_digits.sum())\n",
    "# this will make our embeddings smaller and faster to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 00:47:10.754756\n",
      "Time elapsed: 0:00:00.134627\n",
      "Documents: 1637\n",
      "Words removed with digits only: 19435\n",
      "Total words remaining: 402144\n"
     ]
    }
   ],
   "source": [
    "# we might still have words that contain a digit in them let's remove those as well\n",
    "# let's build a function that will remove any words that contain digits\n",
    "def remove_words_with_digits(words):\n",
    "    \"\"\"Removes words that contain digits from a list of words\"\"\"\n",
    "    return [word for word in words if not any(char.isdigit() for char in word)] # this is slower but more general that previous function\n",
    "\n",
    "# let's apply it to our dataframe\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "df.words_lemmatized = df.words_lemmatized.apply(remove_words_with_digits)\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# let's update our word count cleaned no digits column\n",
    "df[\"word_count_cleaned_no_digits\"] = df.words_lemmatized.apply(len)\n",
    "# let's see how many documents we have now\n",
    "print(\"Documents:\", df.shape[0])\n",
    "# how many words did we remove?\n",
    "print(\"Words removed with digits only:\", df.word_count_cleaned.sum() - df.word_count_cleaned_no_digits.sum())\n",
    "# total words remaining\n",
    "print(\"Total words remaining:\", df.word_count_cleaned_no_digits.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "The simplest way to build embeddings is to use a bag of words model. This is a simple model that counts the number of times each word appears in a document. It then uses these counts to build a vector representation of the document.\n",
    "\n",
    "We will use the gensim library to build our embeddings. Gensim is a library for topic modelling, document indexing and similarity retrieval with large corpora. It uses the word2vec algorithm to create vector representations of words, which can then be used to find words with similar meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count in bow vectorizer 18093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('st', 15191),\n",
       " ('leonard', 9450),\n",
       " ('eastcheap', 5131),\n",
       " ('indict', 8306),\n",
       " ('feloniously', 5881),\n",
       " ('steal', 15305),\n",
       " ('pound', 12590),\n",
       " ('weight', 17460),\n",
       " ('tobacco', 16298),\n",
       " ('value', 16988),\n",
       " ('good', 6844),\n",
       " ('job', 8747),\n",
       " ('wick', 17671),\n",
       " ('dwelling', 5084),\n",
       " ('house', 7957),\n",
       " ('say', 14094),\n",
       " ('april', 626),\n",
       " ('appear', 583),\n",
       " ('prisoner', 12747),\n",
       " ('prosecutor', 12842)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use scikit learn count vectorizer to get a bag of words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# now we will use CountVectorizer to get a bag of words representation\n",
    "\n",
    "# we will use the words_lemmatized column\n",
    "# we will use the default tokenizer\n",
    "# we will use the default vocabulary\n",
    "# we will use the default ngram_range\n",
    "\n",
    "# let's create an instance of CountVectorizer\n",
    "count_vectorizer = CountVectorizer() # there area many custom parameters we can set, but we will use defaults for now\n",
    "# if you check the documentation you will see that many of the tasks we did previously can be done with CountVectorizer such as tokenization, stopword removal, etc.\n",
    "# docs: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "# let's fit it to our words_lemmatized column\n",
    "# we will need to convert it back to a string with space separated words\n",
    "# we can use apply and join to do this\n",
    "count_vectorizer.fit(df.words_lemmatized.apply(\" \".join)) # fit is often used in scikit learn to learn the vocabulary, fit is also used in training models\n",
    "# above might seem a bit wasteful, but it is a common pattern in scikit learn\n",
    "\n",
    "# let's see what we have in our vocabulary\n",
    "# how many unique words do we have?\n",
    "print(\"Word count in bow vectorizer\", len(count_vectorizer.vocabulary_)) # this will return a dictionary with words as keys and their index as values\n",
    "# first 20 words\n",
    "list(count_vectorizer.vocabulary_.items())[:20]# this will return a dictionary with words as keys and their index as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18093"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique words do we have?\n",
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st',\n",
       " 'leonard',\n",
       " 'eastcheap',\n",
       " 'indict',\n",
       " 'feloniously',\n",
       " 'steal',\n",
       " 'pound',\n",
       " 'weight',\n",
       " 'tobacco',\n",
       " 'value',\n",
       " 'l',\n",
       " 's',\n",
       " 'good',\n",
       " 'job',\n",
       " 'wick',\n",
       " 'dwelling',\n",
       " 'house',\n",
       " 'say',\n",
       " 'job',\n",
       " 'wick',\n",
       " 'april',\n",
       " 'appear',\n",
       " 'prisoner',\n",
       " 'prosecutor',\n",
       " 'servant',\n",
       " 'fellow',\n",
       " 'servant',\n",
       " 'depose',\n",
       " 'perceive',\n",
       " 'pocket',\n",
       " 'stick',\n",
       " 'search',\n",
       " 'find',\n",
       " 'paper',\n",
       " 'tobacco',\n",
       " 'worth',\n",
       " 'd',\n",
       " 'own',\n",
       " 'master',\n",
       " 'take',\n",
       " 'cellar',\n",
       " 'constable',\n",
       " 'depose',\n",
       " 'confest',\n",
       " 'take',\n",
       " 'tobacco',\n",
       " 'time',\n",
       " 'say',\n",
       " 'paper',\n",
       " 'tobacco',\n",
       " 'produce',\n",
       " 'court',\n",
       " 'jury',\n",
       " 'consider',\n",
       " 'matter',\n",
       " 'find',\n",
       " 'guilty',\n",
       " 'value',\n",
       " 'd',\n",
       " 'transportation']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can we get a bag of words representation for a single document?\n",
    "# let's get the first document\n",
    "# get words from first row\n",
    "first_doc = df.words_lemmatized.iloc[0] # iloc is used to get row by numerical index\n",
    "# let's see what it looks like\n",
    "first_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x18093 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 44 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get bag of words representation of first document\n",
    "first_doc_bow = count_vectorizer.transform([\" \".join(first_doc)]) # we need to pass a list of documents\n",
    "# this will return a sparse matrix\n",
    "first_doc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  583   626  2732  3513  3577  3595  3837  4445  5084  5131  5870  5881\n",
      "  5983  6844  7090  7957  8306  8747  8860  9450 10216 10239 11682 11770\n",
      " 12050 12408 12590 12747 12786 12842 14094 14233 14364 15191 15305 15356\n",
      " 15847 16262 16298 16468 16988 17460 17671 17956]\n"
     ]
    }
   ],
   "source": [
    "# print element indexes of sparse matrix\n",
    "print(first_doc_bow.indices)\n",
    "# sparse matrix is a matrix that has many zero elements so those are generally not stored and are skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['appear', 'april', 'cellar', 'confest', 'consider', 'constable',\n",
       "       'court', 'depose', 'dwelling', 'eastcheap', 'fellow',\n",
       "       'feloniously', 'find', 'good', 'guilty', 'house', 'indict', 'job',\n",
       "       'jury', 'leonard', 'master', 'matter', 'own', 'paper', 'perceive',\n",
       "       'pocket', 'pound', 'prisoner', 'produce', 'prosecutor', 'say',\n",
       "       'search', 'servant', 'st', 'steal', 'stick', 'take', 'time',\n",
       "       'tobacco', 'transportation', 'value', 'weight', 'wick', 'worth'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are those words from indices?\n",
    "# we can use get_feature_names method\n",
    "count_vectorizer.get_feature_names_out()[first_doc_bow.indices]\n",
    "\n",
    "# note get_features_names was depreceated in favor of get_feature_names_out\n",
    "\n",
    "# now results show that we have the same words as in our first document except the order is different\n",
    "# here it looks like we have a bag of words representation for a single document in our corpus in an ordered list of words by lexical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could create a huge sparse matrix for each document in our corpus\n",
    "# however that would not be particularly useful\n",
    "# we already saw that most of the words in our vocabulary are quite rare\n",
    "\n",
    "# armed with these embbeddings we could compare documents by things like jaccard similarity\n",
    "# jackquard similarity is a measure of how similar two sets are\n",
    "# we could also use cosine similarity but that is a bit more complicated for now\n",
    "\n",
    "# luckily we have many more options for creating embeddings beyond bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF embeddings\n",
    "\n",
    "TF-IDF is a widely used technique for text analysis. It stands for term frequency-inverse document frequency. It is a way of measuring how important a word is to a document in a collection of documents. It is often used to find keywords in a document.\n",
    "\n",
    "TF-IDF consists of two parts: term frequency and inverse document frequency. Term frequency is the number of times a word appears in a document, while inverse document frequency is the number of documents in a collection that contain a word. The TF-IDF score is the product of these two numbers.\n",
    "\n",
    "The idea is that first part - TF - is the number of times a word appears in a document, and the bottom part - IDF - is the number of documents in a collection that contain a word. The TF-IDF score is the product of these two numbers.\n",
    "\n",
    "If IDF is high - this means the word is not particularly common in the collection of documents. If TF is high - this means the word is common in the document. So if a word is common in a document, but not common in the collection of documents, it will have a high TF-IDF score - ergo this word is common to the document, but not common to the collection of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use tfidf to create embeddings\n",
    "\n",
    "# scikit learn has a tfidf vectorizer\n",
    "\n",
    "# let's create an instance of tfidf vectorizer\n",
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer() # there area many custom parameters we can set, but we will use defaults for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words: 18093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('st', 15191),\n",
       " ('leonard', 9450),\n",
       " ('eastcheap', 5131),\n",
       " ('indict', 8306),\n",
       " ('feloniously', 5881),\n",
       " ('steal', 15305),\n",
       " ('pound', 12590),\n",
       " ('weight', 17460),\n",
       " ('tobacco', 16298),\n",
       " ('value', 16988),\n",
       " ('good', 6844),\n",
       " ('job', 8747),\n",
       " ('wick', 17671),\n",
       " ('dwelling', 5084),\n",
       " ('house', 7957),\n",
       " ('say', 14094),\n",
       " ('april', 626),\n",
       " ('appear', 583),\n",
       " ('prisoner', 12747),\n",
       " ('prosecutor', 12842)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create tfidf embeddings for our corpus\n",
    "# we will use the words_lemmatized column\n",
    "\n",
    "# let's fit it to our words_lemmatized column\n",
    "# we will need to convert it back to a string with space separated words\n",
    "\n",
    "# we can use apply and join to do this\n",
    "tfidf_vectorizer.fit(df.words_lemmatized.apply(\" \".join)) # fit is often used in scikit learn to learn the vocabulary, fit is also used in training models\n",
    "\n",
    "# let's see what we have in our vocabulary\n",
    "# how many unique words do we have?\n",
    "print(\"Unique words:\", len(tfidf_vectorizer.vocabulary_))\n",
    "# first 20 words\n",
    "list(tfidf_vectorizer.vocabulary_.items())[:20]# this will return a dictionary with words as keys and their index as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17956 17671 17460 16988 16468 16298 16262 15847 15356 15305 15191 14364\n",
      " 14233 14094 12842 12786 12747 12590 12408 12050 11770 11682 10239 10216\n",
      "  9450  8860  8747  8306  7957  7090  6844  5983  5881  5870  5131  5084\n",
      "  4445  3837  3595  3577  3513  2732   626   583]\n"
     ]
    }
   ],
   "source": [
    "# Attentive of you have noticed that both bow and tfidf vectorizers have the same vocabulary, which makes sense as we used same data to fit them\n",
    "# also we used same hyper parameters for fitting so they should be the same \n",
    "# in this case we used default hyper parameters - which means we only used unigrams\n",
    "\n",
    "# now let's create tifidf embeddings for our corpus\n",
    "\n",
    "# we will use the transform method\n",
    "\n",
    "# let's get the first document\n",
    "# get words from first row\n",
    "first_doc = df.words_lemmatized.iloc[0] # iloc is used to get row by numerical index\n",
    "# let's see what it looks like\n",
    "# show tfidf embeddings for first document\n",
    "sparse_tfidf_first_doc = tfidf_vectorizer.transform([\" \".join(first_doc)])\n",
    "\n",
    "# print element indexes of sparse matrix\n",
    "print(sparse_tfidf_first_doc.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common indices: {16262, 17671, 3595, 5131, 14094, 12050, 7957, 5881, 14233, 8860, 14364, 11682, 17956, 16298, 12842, 8747, 2732, 12590, 7090, 17460, 3513, 6844, 583, 15305, 12747, 16468, 15191, 16988, 5084, 4445, 5983, 15847, 10216, 9450, 5870, 12786, 8306, 626, 12408, 3577, 11770, 15356, 3837, 10239}\n",
      "Common indices: 44 44 44\n"
     ]
    }
   ],
   "source": [
    "# compare indices of tfidf and bow\n",
    "common_indices = set(first_doc_bow.indices).intersection(set(sparse_tfidf_first_doc.indices))\n",
    "print(\"Common indices:\", common_indices)\n",
    "# length of common indices and length of tfidf indices and bow indices\n",
    "print(\"Common indices:\", len(common_indices), len(sparse_tfidf_first_doc.indices), len(first_doc_bow.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0976779  0.37167729 0.1152001  0.09338854 0.09667718 0.54500717\n",
      " 0.05984298 0.0880047  0.12253903 0.03811135 0.0725742  0.1623928\n",
      " 0.07622164 0.08669131 0.06912378 0.06048691 0.03825868 0.09590149\n",
      " 0.07474145 0.15061469 0.18846137 0.12918558 0.10184287 0.08108325\n",
      " 0.16007528 0.05287715 0.26499458 0.03752959 0.05520719 0.03137085\n",
      " 0.04642964 0.09419189 0.06070487 0.12566637 0.18583865 0.1396641\n",
      " 0.21576343 0.07063989 0.07788469 0.11371992 0.19723912 0.13877142\n",
      " 0.10001348 0.08560634]\n"
     ]
    }
   ],
   "source": [
    "# well the indices are all common,but bag of words either has count for word or not\n",
    "# tfidf has a value for each word which indicates how important that word is for that document\n",
    "# let's print those values for first doc\n",
    "print(sparse_tfidf_first_doc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 24 11 34 20 40 36 26  1  5]\n"
     ]
    }
   ],
   "source": [
    "# what are most important words for first document?\n",
    "# let's get indices of top 10 most important words\n",
    "top_10_indices = np.argsort(sparse_tfidf_first_doc.data)[-10:]\n",
    "print(top_10_indices)\n",
    "# now these are indices of top 10 most important words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15061469 0.16007528 0.1623928  0.18583865 0.18846137 0.19723912\n",
      " 0.21576343 0.26499458 0.37167729 0.54500717]\n"
     ]
    }
   ],
   "source": [
    "# top 10 most important words values\n",
    "print(sparse_tfidf_first_doc.data[top_10_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12050  9450 14364  5131 11770  3513  4445  8747 17671 16298]\n"
     ]
    }
   ],
   "source": [
    "# let's print word indexes for these top 10 words\n",
    "print(sparse_tfidf_first_doc.indices[top_10_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceive 0.15061468637250305\n",
      "leonard 0.16007528280052977\n",
      "servant 0.16239279925933373\n",
      "eastcheap 0.1858386471483628\n",
      "paper 0.18846136671056882\n",
      "confest 0.1972391174872452\n",
      "depose 0.21576343212843113\n",
      "job 0.2649945751946771\n",
      "wick 0.3716772942967256\n",
      "tobacco 0.5450071694542097\n"
     ]
    }
   ],
   "source": [
    "# that is not so nice looking so we can zip them together\n",
    "# list(zip(tfidf_vectorizer.get_feature_names_out()[top_10_indices], sparse_tfidf_first_doc.data[top_10_indices]))\n",
    "# print them in a nicer way\n",
    "top_10_word_indexes = sparse_tfidf_first_doc.indices[top_10_indices]\n",
    "for word, tfidf in zip(tfidf_vectorizer.get_feature_names_out()[top_10_word_indexes], sparse_tfidf_first_doc.data[top_10_indices]):\n",
    "    print(word, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that tfidf embeddings are much more informative than bag of words embeddings\n",
    "# we can find the most important words for each document\n",
    "# tfidf is great because it will automatically filter out stopwords and rare words\n",
    "# using scikit learn indexing can get pretty tricky though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confest', 0.1972391174872452),\n",
       " ('depose', 0.21576343212843113),\n",
       " ('job', 0.2649945751946771),\n",
       " ('wick', 0.3716772942967256),\n",
       " ('tobacco', 0.5450071694542097)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get top 5 words for each document\n",
    "# we will need to iterate over each document\n",
    "# we will need to get tfidf embeddings for each document\n",
    "\n",
    "# let's create a function that will return top n words for a document\n",
    "def get_top_n_words(document, n=5):\n",
    "    \"\"\"Returns top n words for a document\"\"\"\n",
    "    # get tfidf embeddings for document\n",
    "    sparse_tfidf_doc = tfidf_vectorizer.transform([\" \".join(document)])\n",
    "    # get indices of top n words\n",
    "    top_n_indices = np.argsort(sparse_tfidf_doc.data)[-n:]\n",
    "    # get word indexes for top n words\n",
    "    top_n_word_indexes = sparse_tfidf_doc.indices[top_n_indices]\n",
    "    # get top n words\n",
    "    top_n_words = tfidf_vectorizer.get_feature_names_out()[top_n_word_indexes]\n",
    "    # get top n tfidf values\n",
    "    top_n_tfidf = sparse_tfidf_doc.data[top_n_indices]\n",
    "    # return top n words and top n tfidf values\n",
    "    return list(zip(top_n_words, top_n_tfidf))\n",
    "\n",
    "# let's test it on first document\n",
    "get_top_n_words(first_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:17:33.674921\n",
      "Time elapsed: 0:00:08.569515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1637, 11)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can apply it to our dataframe\n",
    "# we will use apply method\n",
    "# we will use lambda function\n",
    "\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "df[\"top_5_words_tfidf\"] = df.words_lemmatized.apply(lambda x: get_top_n_words(x, n=5))\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# print shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_number</th>\n",
       "      <th>punishment</th>\n",
       "      <th>text</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>words_lemmatized</th>\n",
       "      <th>word_count_cleaned_no_digits</th>\n",
       "      <th>top_5_words_tfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>27</td>\n",
       "      <td>Three months' imprisonment in the second division</td>\n",
       "      <td>592 archibald malcolm steward 18 forging and u...</td>\n",
       "      <td>5204</td>\n",
       "      <td>4980</td>\n",
       "      <td>[592, archibald, malcolm, steward, 18, forging...</td>\n",
       "      <td>957</td>\n",
       "      <td>417</td>\n",
       "      <td>[archibald, malcolm, steward, forge, utter, au...</td>\n",
       "      <td>401</td>\n",
       "      <td>[(office, 0.18194225183146617), (book, 0.25306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>63</td>\n",
       "      <td>Transported for Seven Years — Convict Ship</td>\n",
       "      <td>360 henry butler was indicted for stealing on ...</td>\n",
       "      <td>1197</td>\n",
       "      <td>1141</td>\n",
       "      <td>[360, henry, butler, indicted, stealing, 14th,...</td>\n",
       "      <td>217</td>\n",
       "      <td>95</td>\n",
       "      <td>[henry, butler, indict, steal, december, weigh...</td>\n",
       "      <td>90</td>\n",
       "      <td>[(coal, 0.19814038693423272), (charlotte, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>113</td>\n",
       "      <td>None</td>\n",
       "      <td>678 william jones 38 a negro for the manslaugh...</td>\n",
       "      <td>145</td>\n",
       "      <td>133</td>\n",
       "      <td>[678, william, jones, 38, negro, manslaughter,...</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>[william, jones, negro, manslaughter, herbert,...</td>\n",
       "      <td>12</td>\n",
       "      <td>[(herbert, 0.3214283443450827), (manslaughter,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>34</td>\n",
       "      <td>None</td>\n",
       "      <td>312 john hyland 35 was indicted for and charge...</td>\n",
       "      <td>14103</td>\n",
       "      <td>13679</td>\n",
       "      <td>[312, john, hyland, 35, indicted, charged, cor...</td>\n",
       "      <td>2673</td>\n",
       "      <td>994</td>\n",
       "      <td>[john, hyland, indict, charge, coroner, inquis...</td>\n",
       "      <td>986</td>\n",
       "      <td>[(lung, 0.1839644163157637), (food, 0.18967954...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>43</td>\n",
       "      <td>Transported for Seven Years</td>\n",
       "      <td>114 james hawkins was indicted for feloniously...</td>\n",
       "      <td>1387</td>\n",
       "      <td>1339</td>\n",
       "      <td>[114, james, hawkins, indicted, feloniously, s...</td>\n",
       "      <td>256</td>\n",
       "      <td>117</td>\n",
       "      <td>[james, hawkins, indict, feloniously, steal, d...</td>\n",
       "      <td>111</td>\n",
       "      <td>[(see, 0.17690868106143018), (step, 0.17693100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trial_number                                         punishment  \\\n",
       "year                                                                    \n",
       "1902            27  Three months' imprisonment in the second division   \n",
       "1841            63         Transported for Seven Years — Convict Ship   \n",
       "1902           113                                               None   \n",
       "1865            34                                               None   \n",
       "1814            43                        Transported for Seven Years   \n",
       "\n",
       "                                                   text  dirty_len  clean_len  \\\n",
       "year                                                                            \n",
       "1902  592 archibald malcolm steward 18 forging and u...       5204       4980   \n",
       "1841  360 henry butler was indicted for stealing on ...       1197       1141   \n",
       "1902  678 william jones 38 a negro for the manslaugh...        145        133   \n",
       "1865  312 john hyland 35 was indicted for and charge...      14103      13679   \n",
       "1814  114 james hawkins was indicted for feloniously...       1387       1339   \n",
       "\n",
       "                                                  words  word_count  \\\n",
       "year                                                                  \n",
       "1902  [592, archibald, malcolm, steward, 18, forging...         957   \n",
       "1841  [360, henry, butler, indicted, stealing, 14th,...         217   \n",
       "1902  [678, william, jones, 38, negro, manslaughter,...          22   \n",
       "1865  [312, john, hyland, 35, indicted, charged, cor...        2673   \n",
       "1814  [114, james, hawkins, indicted, feloniously, s...         256   \n",
       "\n",
       "      word_count_cleaned                                   words_lemmatized  \\\n",
       "year                                                                          \n",
       "1902                 417  [archibald, malcolm, steward, forge, utter, au...   \n",
       "1841                  95  [henry, butler, indict, steal, december, weigh...   \n",
       "1902                  14  [william, jones, negro, manslaughter, herbert,...   \n",
       "1865                 994  [john, hyland, indict, charge, coroner, inquis...   \n",
       "1814                 117  [james, hawkins, indict, feloniously, steal, d...   \n",
       "\n",
       "      word_count_cleaned_no_digits  \\\n",
       "year                                 \n",
       "1902                           401   \n",
       "1841                            90   \n",
       "1902                            12   \n",
       "1865                           986   \n",
       "1814                           111   \n",
       "\n",
       "                                      top_5_words_tfidf  \n",
       "year                                                     \n",
       "1902  [(office, 0.18194225183146617), (book, 0.25306...  \n",
       "1841  [(coal, 0.19814038693423272), (charlotte, 0.21...  \n",
       "1902  [(herbert, 0.3214283443450827), (manslaughter,...  \n",
       "1865  [(lung, 0.1839644163157637), (food, 0.18967954...  \n",
       "1814  [(see, 0.17690868106143018), (step, 0.17693100...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what we have\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:21:21.002552\n",
      "Time elapsed: 0:00:00.577069\n",
      "File size: 3319544\n"
     ]
    }
   ],
   "source": [
    "# we would love to save our data to parquet file but alas we have datatypes that are not supported by parquet\n",
    "# thus we will use pickle that will faithfully save everything\n",
    "# we will use to_pickle method\n",
    "# we will use compression to save space\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "pickle_file = Path(\"old_bailey_sample_1720_1913_cleaned_embeddings.pkl\")\n",
    "print(f\"Start time: {start}\")\n",
    "df.to_pickle(pickle_file, compression=\"zip\")\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# how big is our file?\n",
    "print(\"File size:\", pickle_file.stat().st_size)\n",
    "# not too bad a compression ratio and we kept all our data and datatypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec embeddings\n",
    "\n",
    "word2vec embeddings is a technique for creating word embeddings. It is a neural network model that takes a word as input and outputs a vector representation of that word. The word2vec model is trained on a large corpus of text, and learns to predict the context of a word based on its vector representation.\n",
    "\n",
    "word2vec came to prominence in 2013, when Google released a paper describing the model. It has since been used in many applications, including machine translation, sentiment analysis, and text classification.\n",
    "\n",
    "Original Google paper: Efficient Estimation of Word Representations in\n",
    "Vector Space https://arxiv.org/pdf/1301.3781.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:47:34.814711\n",
      "Time elapsed: 0:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['st',\n",
       "  'leonard',\n",
       "  'eastcheap',\n",
       "  'indict',\n",
       "  'feloniously',\n",
       "  'steal',\n",
       "  'pound',\n",
       "  'weight',\n",
       "  'tobacco',\n",
       "  'value',\n",
       "  'l',\n",
       "  's',\n",
       "  'good',\n",
       "  'job',\n",
       "  'wick',\n",
       "  'dwelling',\n",
       "  'house',\n",
       "  'say',\n",
       "  'job',\n",
       "  'wick',\n",
       "  'april',\n",
       "  'appear',\n",
       "  'prisoner',\n",
       "  'prosecutor',\n",
       "  'servant',\n",
       "  'fellow',\n",
       "  'servant',\n",
       "  'depose',\n",
       "  'perceive',\n",
       "  'pocket',\n",
       "  'stick',\n",
       "  'search',\n",
       "  'find',\n",
       "  'paper',\n",
       "  'tobacco',\n",
       "  'worth',\n",
       "  'd',\n",
       "  'own',\n",
       "  'master',\n",
       "  'take',\n",
       "  'cellar',\n",
       "  'constable',\n",
       "  'depose',\n",
       "  'confest',\n",
       "  'take',\n",
       "  'tobacco',\n",
       "  'time',\n",
       "  'say',\n",
       "  'paper',\n",
       "  'tobacco',\n",
       "  'produce',\n",
       "  'court',\n",
       "  'jury',\n",
       "  'consider',\n",
       "  'matter',\n",
       "  'find',\n",
       "  'guilty',\n",
       "  'value',\n",
       "  'd',\n",
       "  'transportation'],\n",
       " ['alice',\n",
       "  'jones',\n",
       "  'st',\n",
       "  'michaels',\n",
       "  'cornhill',\n",
       "  'indict',\n",
       "  'privately',\n",
       "  'steal',\n",
       "  'bermundas',\n",
       "  'hat',\n",
       "  'value',\n",
       "  's',\n",
       "  'shop',\n",
       "  'edward',\n",
       "  'hillior',\n",
       "  'april',\n",
       "  'prosecutors',\n",
       "  'servant',\n",
       "  'deposed',\n",
       "  'prisner',\n",
       "  'come',\n",
       "  'master',\n",
       "  'shop',\n",
       "  'askd',\n",
       "  'hat',\n",
       "  's',\n",
       "  'price',\n",
       "  'shew',\n",
       "  'agreed',\n",
       "  'say',\n",
       "  'country',\n",
       "  'stop',\n",
       "  'bishopsgatestreet',\n",
       "  'coach',\n",
       "  'go',\n",
       "  'come',\n",
       "  'fetch',\n",
       "  'go',\n",
       "  'shop',\n",
       "  'perceive',\n",
       "  'hardly',\n",
       "  'walk',\n",
       "  'fetcht',\n",
       "  'hat',\n",
       "  'mention',\n",
       "  'indictment',\n",
       "  'fall',\n",
       "  'leg',\n",
       "  'depose',\n",
       "  'see',\n",
       "  'evidence',\n",
       "  'hat',\n",
       "  'petticoat',\n",
       "  'prisoner',\n",
       "  'deny',\n",
       "  'fact',\n",
       "  'call',\n",
       "  'person',\n",
       "  'reputation',\n",
       "  'give',\n",
       "  'good',\n",
       "  'character',\n",
       "  'say',\n",
       "  'rent',\n",
       "  'house',\n",
       "  'l',\n",
       "  'year',\n",
       "  'petty',\n",
       "  'france',\n",
       "  'westminster',\n",
       "  'tell',\n",
       "  'justice',\n",
       "  'livd',\n",
       "  'kingstreet',\n",
       "  'jury',\n",
       "  'consider',\n",
       "  'matter',\n",
       "  'find',\n",
       "  'guilty',\n",
       "  'value',\n",
       "  'd',\n",
       "  'transportation'],\n",
       " ['james',\n",
       "  'wilson',\n",
       "  'st',\n",
       "  'katharine',\n",
       "  'coleman',\n",
       "  'indict',\n",
       "  'feloniously',\n",
       "  'steal',\n",
       "  'pound',\n",
       "  'beef',\n",
       "  'value',\n",
       "  's',\n",
       "  'good',\n",
       "  'charle',\n",
       "  'watts',\n",
       "  'april',\n",
       "  'mary',\n",
       "  'watts',\n",
       "  'deposed',\n",
       "  'gentleman',\n",
       "  'come',\n",
       "  'bar',\n",
       "  'clock',\n",
       "  'night',\n",
       "  'tell',\n",
       "  'fellow',\n",
       "  'lurking',\n",
       "  'house',\n",
       "  'prisoner',\n",
       "  'come',\n",
       "  'bar',\n",
       "  'take',\n",
       "  'rump',\n",
       "  'beef',\n",
       "  'hung',\n",
       "  'pursue',\n",
       "  'dropt',\n",
       "  'door',\n",
       "  'see',\n",
       "  'plain',\n",
       "  'sure',\n",
       "  'prisoner',\n",
       "  'person',\n",
       "  'cookmaid',\n",
       "  'deposed',\n",
       "  'see',\n",
       "  'prisoner',\n",
       "  'beef',\n",
       "  'lift',\n",
       "  'times',\n",
       "  'hook',\n",
       "  'prisoner',\n",
       "  'defence',\n",
       "  'say',\n",
       "  'drinking',\n",
       "  'run',\n",
       "  'head',\n",
       "  'beef',\n",
       "  'fall',\n",
       "  'appear',\n",
       "  'evidence',\n",
       "  'dropt',\n",
       "  'yard',\n",
       "  'place',\n",
       "  'hung',\n",
       "  'jury',\n",
       "  'find',\n",
       "  'guilty',\n",
       "  'value',\n",
       "  'd',\n",
       "  'transportation'],\n",
       " ['james',\n",
       "  'mercy',\n",
       "  'alias',\n",
       "  'masse',\n",
       "  'st',\n",
       "  'andrew',\n",
       "  'undershaft',\n",
       "  'indict',\n",
       "  'feloniously',\n",
       "  'steal',\n",
       "  'silk',\n",
       "  'gown',\n",
       "  'petticoat',\n",
       "  'camblet',\n",
       "  'cloak',\n",
       "  'good',\n",
       "  'dwell',\n",
       "  'house',\n",
       "  'mary',\n",
       "  'robinson',\n",
       "  'april',\n",
       "  'prosecutor',\n",
       "  'depose',\n",
       "  'hearing',\n",
       "  'noise',\n",
       "  'stair',\n",
       "  'send',\n",
       "  'maid',\n",
       "  'mary',\n",
       "  'gough',\n",
       "  'depose',\n",
       "  'go',\n",
       "  'find',\n",
       "  'prisoner',\n",
       "  'arm',\n",
       "  'clothe',\n",
       "  'lockd',\n",
       "  'run',\n",
       "  'calld',\n",
       "  'assistance',\n",
       "  'go',\n",
       "  'clothe',\n",
       "  'find',\n",
       "  'wet',\n",
       "  'floor',\n",
       "  'lockt',\n",
       "  'drawer',\n",
       "  'constable',\n",
       "  'depose',\n",
       "  'prisoner',\n",
       "  'shammd',\n",
       "  'drunk',\n",
       "  'find',\n",
       "  'chissel',\n",
       "  'pocket',\n",
       "  'believe',\n",
       "  'opend',\n",
       "  'drawer',\n",
       "  'jury',\n",
       "  'find',\n",
       "  'guilty',\n",
       "  'value',\n",
       "  's',\n",
       "  'transportation'],\n",
       " ['benjamin',\n",
       "  'cook',\n",
       "  'alias',\n",
       "  'richard',\n",
       "  'smith',\n",
       "  'st',\n",
       "  'mary',\n",
       "  'abchurch',\n",
       "  'indict',\n",
       "  'feloniously',\n",
       "  'steal',\n",
       "  'silver',\n",
       "  'cup',\n",
       "  'value',\n",
       "  's',\n",
       "  'good',\n",
       "  'philip',\n",
       "  'austin',\n",
       "  'march',\n",
       "  'prosecutor',\n",
       "  'depose',\n",
       "  'lose',\n",
       "  'cup',\n",
       "  'kitchen',\n",
       "  'produce',\n",
       "  'court',\n",
       "  'swear',\n",
       "  'goldsmith',\n",
       "  'depose',\n",
       "  'prisoner',\n",
       "  'offer',\n",
       "  'sell',\n",
       "  'stopt',\n",
       "  'send',\n",
       "  'mr',\n",
       "  'austin',\n",
       "  'own',\n",
       "  'jury',\n",
       "  'find',\n",
       "  'guilty',\n",
       "  'value',\n",
       "  'd',\n",
       "  'transportation']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use gensim to create word2vec embeddings for our whole corpus\n",
    "\n",
    "# we will use the words_lemmatized column\n",
    "# we will use the default tokenizer\n",
    "# we will use the default vocabulary\n",
    "# we will use the default ngram_range\n",
    "\n",
    "# we need to use a list of lists of words\n",
    "# we can use apply and split to do this\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "# sentences = df.words_lemmatized.apply(lambda x: x.split()).tolist() # we would use this if our words were a string separated by spaces\n",
    "sentences = df.words_lemmatized.tolist()\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# let's see what we have\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:27:22.359416\n",
      "Time elapsed: 0:00:00.566596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x149998fc910>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's feed our sentences to gensim word2vec model\n",
    "# we will use default hyper parameters\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "w2v_model = gensim.models.Word2Vec(sentences=sentences)\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# cool think about word2vec is that it trains very fast - unlike more modern embeddings such as BERT\n",
    "# let's see what we have\n",
    "w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crickett', 0.9563700556755066),\n",
       " ('m', 0.9443530440330505),\n",
       " ('highway', 0.9437509775161743),\n",
       " ('bride', 0.9414304494857788),\n",
       " ('botolph', 0.9367403984069824),\n",
       " ('martin', 0.9357951283454895),\n",
       " ('elizabeth', 0.9232580661773682),\n",
       " ('cochran', 0.9215368032455444),\n",
       " ('draper', 0.9182206988334656),\n",
       " ('housesurgeon', 0.9156031608581543)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now use our model to get embeddings for words\n",
    "# we can compare words by similarity\n",
    "# we can get most similar words\n",
    "\n",
    "# let's try king and queen\n",
    "w2v_model.wv.most_similar(\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oxford', 0.988685667514801),\n",
       " ('clements', 0.9867776036262512),\n",
       " ('griffin', 0.9822165369987488),\n",
       " ('shoreditch', 0.97926265001297),\n",
       " ('euston', 0.9788939952850342),\n",
       " ('sepulchres', 0.9780794978141785),\n",
       " ('high', 0.9776077270507812),\n",
       " ('bell', 0.9775933623313904),\n",
       " ('hoxton', 0.975581705570221),\n",
       " ('park', 0.9755066633224487)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how about queen\n",
    "w2v_model.wv.most_similar(\"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit surprising but then again court transcripts seldom deal with royalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cloak', 0.9726721048355103),\n",
       " ('breeche', 0.9662832617759705),\n",
       " ('apron', 0.9648007154464722),\n",
       " ('shoe', 0.9623876810073853),\n",
       " ('loaf', 0.9599335789680481),\n",
       " ('ribbon', 0.9596375823020935),\n",
       " ('tester', 0.9571384191513062),\n",
       " ('bonnet', 0.955176830291748),\n",
       " ('shirt', 0.9530536532402039),\n",
       " ('breech', 0.9525079131126404)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how about tobacco?\n",
    "w2v_model.wv.most_similar(\"tobacco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pint', 0.9907461404800415),\n",
       " ('gin', 0.9567537903785706),\n",
       " ('ale', 0.9548437595367432),\n",
       " ('fetch', 0.94757080078125),\n",
       " ('drank', 0.9215078353881836),\n",
       " ('spare', 0.9210358262062073),\n",
       " ('soon', 0.9174252152442932),\n",
       " ('went', 0.9143045544624329),\n",
       " ('rum', 0.9140437841415405),\n",
       " ('drink', 0.9110946655273438)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how about beer?\n",
    "w2v_model.wv.most_similar(\"beer\")\n",
    "# now we are talking! or drinking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1637\n",
      "Min sentence length: 5\n",
      "Max sentence length: 11127\n"
     ]
    }
   ],
   "source": [
    "# let's check dimensions of our sentences\n",
    "print(\"Sentences:\", len(sentences))\n",
    "# how about min and max of sentence lengths\n",
    "print(\"Min sentence length:\", min([len(sentence) for sentence in sentences]))\n",
    "print(\"Max sentence length:\", max([len(sentence) for sentence in sentences]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:47:44.525945\n",
      "Time elapsed: 0:00:00.001000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['st', 'leonard', 'eastcheap', 'indict', 'feloniously', 'steal', 'pound', 'weight', 'tobacco', 'value', 'l', 's', 'good', 'job', 'wick', 'dwelling', 'house', 'say', 'job', 'wick', 'april', 'appear', 'prisoner', 'prosecutor', 'servant', 'fellow', 'servant', 'depose', 'perceive', 'pocket', 'stick', 'search', 'find', 'paper', 'tobacco', 'worth', 'd', 'own', 'master', 'take', 'cellar', 'constable', 'depose', 'confest', 'take', 'tobacco', 'time', 'say', 'paper', 'tobacco', 'produce', 'court', 'jury', 'consider', 'matter', 'find', 'guilty', 'value', 'd', 'transportation'], tags=[0]),\n",
       " TaggedDocument(words=['alice', 'jones', 'st', 'michaels', 'cornhill', 'indict', 'privately', 'steal', 'bermundas', 'hat', 'value', 's', 'shop', 'edward', 'hillior', 'april', 'prosecutors', 'servant', 'deposed', 'prisner', 'come', 'master', 'shop', 'askd', 'hat', 's', 'price', 'shew', 'agreed', 'say', 'country', 'stop', 'bishopsgatestreet', 'coach', 'go', 'come', 'fetch', 'go', 'shop', 'perceive', 'hardly', 'walk', 'fetcht', 'hat', 'mention', 'indictment', 'fall', 'leg', 'depose', 'see', 'evidence', 'hat', 'petticoat', 'prisoner', 'deny', 'fact', 'call', 'person', 'reputation', 'give', 'good', 'character', 'say', 'rent', 'house', 'l', 'year', 'petty', 'france', 'westminster', 'tell', 'justice', 'livd', 'kingstreet', 'jury', 'consider', 'matter', 'find', 'guilty', 'value', 'd', 'transportation'], tags=[1]),\n",
       " TaggedDocument(words=['james', 'wilson', 'st', 'katharine', 'coleman', 'indict', 'feloniously', 'steal', 'pound', 'beef', 'value', 's', 'good', 'charle', 'watts', 'april', 'mary', 'watts', 'deposed', 'gentleman', 'come', 'bar', 'clock', 'night', 'tell', 'fellow', 'lurking', 'house', 'prisoner', 'come', 'bar', 'take', 'rump', 'beef', 'hung', 'pursue', 'dropt', 'door', 'see', 'plain', 'sure', 'prisoner', 'person', 'cookmaid', 'deposed', 'see', 'prisoner', 'beef', 'lift', 'times', 'hook', 'prisoner', 'defence', 'say', 'drinking', 'run', 'head', 'beef', 'fall', 'appear', 'evidence', 'dropt', 'yard', 'place', 'hung', 'jury', 'find', 'guilty', 'value', 'd', 'transportation'], tags=[2]),\n",
       " TaggedDocument(words=['james', 'mercy', 'alias', 'masse', 'st', 'andrew', 'undershaft', 'indict', 'feloniously', 'steal', 'silk', 'gown', 'petticoat', 'camblet', 'cloak', 'good', 'dwell', 'house', 'mary', 'robinson', 'april', 'prosecutor', 'depose', 'hearing', 'noise', 'stair', 'send', 'maid', 'mary', 'gough', 'depose', 'go', 'find', 'prisoner', 'arm', 'clothe', 'lockd', 'run', 'calld', 'assistance', 'go', 'clothe', 'find', 'wet', 'floor', 'lockt', 'drawer', 'constable', 'depose', 'prisoner', 'shammd', 'drunk', 'find', 'chissel', 'pocket', 'believe', 'opend', 'drawer', 'jury', 'find', 'guilty', 'value', 's', 'transportation'], tags=[3]),\n",
       " TaggedDocument(words=['benjamin', 'cook', 'alias', 'richard', 'smith', 'st', 'mary', 'abchurch', 'indict', 'feloniously', 'steal', 'silver', 'cup', 'value', 's', 'good', 'philip', 'austin', 'march', 'prosecutor', 'depose', 'lose', 'cup', 'kitchen', 'produce', 'court', 'swear', 'goldsmith', 'depose', 'prisoner', 'offer', 'sell', 'stopt', 'send', 'mr', 'austin', 'own', 'jury', 'find', 'guilty', 'value', 'd', 'transportation'], tags=[4])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So word 2 vec is a great way to get embeddings for words, but we would like to get embeddings for documents\n",
    "# we can do that by averaging word embeddings for each document\n",
    "# but also we can use doc2vec which is an extension of word2vec\n",
    "\n",
    "# more info: https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "# let's use doc2vec to get embeddings for our corpus\n",
    "\n",
    "# we will use the words_lemmatized column\n",
    "\n",
    "# we need to use a list of lists of words\n",
    "\n",
    "# we already have sentences variable from previous example\n",
    "# it is a list of lists\n",
    "# first index represents document\n",
    "\n",
    "# let's feed our sentences to gensim doc2vec model\n",
    "# we will use default hyper parameters\n",
    "\n",
    "# for doc2vec training data we need TaggedDocument objects\n",
    "# we can use gensim TaggedDocument class to create them\n",
    "# we will use apply and split to do this\n",
    "# start of timer\n",
    "tagged_sentences = []\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "# this will be slow as we will iterate over all documents\n",
    "for i, sentence in enumerate(sentences):\n",
    "    tagged_sentences.append(gensim.models.doc2vec.TaggedDocument(sentence, [i])) # we need to pass a list of words and a list of tags\n",
    "\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "\n",
    "# print first 5 sentences\n",
    "tagged_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:49:34.038989\n",
      "Time elapsed: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "# now we are ready to train our doc2vec model\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "d2v_model = gensim.models.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:51:09.768979\n",
      "Time elapsed: 0:00:00.099296\n"
     ]
    }
   ],
   "source": [
    "# now let's train it with our tagged sentences\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "d2v_model.build_vocab(tagged_sentences)\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 1265, 426, 669)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# who key to index \n",
    "d2v_model.wv.key_to_index[\"king\"], d2v_model.wv.key_to_index[\"queen\"], d2v_model.wv.key_to_index[\"beer\"], d2v_model.wv.key_to_index[\"tobacco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('say', 'prisoner', 'do', 'mr')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index to key\n",
    "d2v_model.wv.index_to_key[0], d2v_model.wv.index_to_key[1], d2v_model.wv.index_to_key[2], d2v_model.wv.index_to_key[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:51:55.147662\n",
      "Time elapsed: 0:00:06.317268\n"
     ]
    }
   ],
   "source": [
    "# now we will finaly train our model\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "d2v_model.train(tagged_sentences, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5782519 , -0.7623888 ,  0.6419972 , -0.01352497, -0.02889981,\n",
       "        0.33993718,  0.5432642 , -0.79231936, -0.17276347,  0.2894747 ,\n",
       "       -0.1814085 , -1.173319  , -0.6315174 , -0.39531848, -0.8824809 ,\n",
       "        0.44549268, -0.00762038, -0.2669511 ,  0.2836903 ,  0.31825238,\n",
       "       -0.46722114, -0.12032476,  1.5427929 , -0.16820197, -0.5314884 ,\n",
       "       -1.1173726 , -0.06433648, -1.0612508 ,  0.8740516 ,  0.24408202,\n",
       "        0.44927603, -0.25962996, -0.23105077,  0.64783835,  0.34015447,\n",
       "        0.6314114 ,  0.5084683 , -0.12150066, -0.8327542 , -0.24457273,\n",
       "        0.46525353, -0.43322456,  0.48058265, -0.8931239 , -0.274334  ,\n",
       "       -0.0263922 ,  0.47523484, -0.10395955,  0.0836495 ,  0.5372703 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now each document should have a corresponding vector\n",
    "# let's get this vector for first document\n",
    "d2v_model.dv[0] # old gensim used docvecs instead of dv\n",
    "# basically we have a 50 length vector for each document\n",
    "# we can use cosine similarity to compare documents and find most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many documents do we have?\n",
    "len(d2v_model.dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637, 11)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows in our dataframe?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>trial_number</th>\n",
       "      <th>punishment</th>\n",
       "      <th>text</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>words_lemmatized</th>\n",
       "      <th>word_count_cleaned_no_digits</th>\n",
       "      <th>top_5_words_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1902</td>\n",
       "      <td>87</td>\n",
       "      <td>Eighteen months' hard labour.</td>\n",
       "      <td>652 james harold rogers 34 feloniously shootin...</td>\n",
       "      <td>8320</td>\n",
       "      <td>8033</td>\n",
       "      <td>[652, james, harold, rogers, 34, feloniously, ...</td>\n",
       "      <td>1585</td>\n",
       "      <td>630</td>\n",
       "      <td>[james, harold, rogers, feloniously, shoot, ag...</td>\n",
       "      <td>608</td>\n",
       "      <td>[(prisoner, 0.1678846871306937), (shot, 0.2407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>1865</td>\n",
       "      <td>23</td>\n",
       "      <td>Confined Six Months</td>\n",
       "      <td>301 john sampson letkey 42 pleaded guilty to u...</td>\n",
       "      <td>229</td>\n",
       "      <td>217</td>\n",
       "      <td>[301, john, sampson, letkey, 42, pleaded, guil...</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>[john, sampson, letkey, plead, guilty, unlawfu...</td>\n",
       "      <td>21</td>\n",
       "      <td>[(page, 0.26883588479601345), (robinson, 0.272...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1773</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>696 697 m william waine and joseph fox were in...</td>\n",
       "      <td>205</td>\n",
       "      <td>190</td>\n",
       "      <td>[696, 697, m, william, waine, joseph, fox, ind...</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>[m, william, waine, joseph, fox, indict, steal...</td>\n",
       "      <td>22</td>\n",
       "      <td>[(fox, 0.2993134965977788), (silver, 0.3398557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1881</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>20 george henry new 22 to embezzling 15 s and ...</td>\n",
       "      <td>184</td>\n",
       "      <td>168</td>\n",
       "      <td>[20, george, henry, new, 22, embezzling, 15, s...</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>[george, henry, new, embezzle, s, l, s, d, gre...</td>\n",
       "      <td>19</td>\n",
       "      <td>[(original, 0.2666105486026002), (image, 0.278...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>1881</td>\n",
       "      <td>70</td>\n",
       "      <td>Two Years' Hard Labour each</td>\n",
       "      <td>70 jessie day 29 and fanny rothwell 34 robbery...</td>\n",
       "      <td>267</td>\n",
       "      <td>247</td>\n",
       "      <td>[70, jessie, day, 29, fanny, rothwell, 34, rob...</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>[jessie, day, fanny, rothwell, robbery, violen...</td>\n",
       "      <td>27</td>\n",
       "      <td>[(josiah, 0.2768258289351973), (jessie, 0.2834...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  trial_number                     punishment  \\\n",
       "1530  1902            87  Eighteen months' hard labour.   \n",
       "1182  1865            23            Confined Six Months   \n",
       "381   1773            53                           None   \n",
       "1329  1881            20                           None   \n",
       "1379  1881            70    Two Years' Hard Labour each   \n",
       "\n",
       "                                                   text  dirty_len  clean_len  \\\n",
       "1530  652 james harold rogers 34 feloniously shootin...       8320       8033   \n",
       "1182  301 john sampson letkey 42 pleaded guilty to u...        229        217   \n",
       "381   696 697 m william waine and joseph fox were in...        205        190   \n",
       "1329  20 george henry new 22 to embezzling 15 s and ...        184        168   \n",
       "1379  70 jessie day 29 and fanny rothwell 34 robbery...        267        247   \n",
       "\n",
       "                                                  words  word_count  \\\n",
       "1530  [652, james, harold, rogers, 34, feloniously, ...        1585   \n",
       "1182  [301, john, sampson, letkey, 42, pleaded, guil...          35   \n",
       "381   [696, 697, m, william, waine, joseph, fox, ind...          36   \n",
       "1329  [20, george, henry, new, 22, embezzling, 15, s...          33   \n",
       "1379  [70, jessie, day, 29, fanny, rothwell, 34, rob...          44   \n",
       "\n",
       "      word_count_cleaned                                   words_lemmatized  \\\n",
       "1530                 630  [james, harold, rogers, feloniously, shoot, ag...   \n",
       "1182                  24  [john, sampson, letkey, plead, guilty, unlawfu...   \n",
       "381                   27  [m, william, waine, joseph, fox, indict, steal...   \n",
       "1329                  25  [george, henry, new, embezzle, s, l, s, d, gre...   \n",
       "1379                  32  [jessie, day, fanny, rothwell, robbery, violen...   \n",
       "\n",
       "      word_count_cleaned_no_digits  \\\n",
       "1530                           608   \n",
       "1182                            21   \n",
       "381                             22   \n",
       "1329                            19   \n",
       "1379                            27   \n",
       "\n",
       "                                      top_5_words_tfidf  \n",
       "1530  [(prisoner, 0.1678846871306937), (shot, 0.2407...  \n",
       "1182  [(page, 0.26883588479601345), (robinson, 0.272...  \n",
       "381   [(fox, 0.2993134965977788), (silver, 0.3398557...  \n",
       "1329  [(original, 0.2666105486026002), (image, 0.278...  \n",
       "1379  [(josiah, 0.2768258289351973), (jessie, 0.2834...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is df.index\n",
    "df.index\n",
    "# looks like we started using year as index\n",
    "# let's reset index by moving year to a column\n",
    "df = df.reset_index()\n",
    "# let's see what we have\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 01:56:11.370468\n",
      "Time elapsed: 0:00:00.001672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>trial_number</th>\n",
       "      <th>punishment</th>\n",
       "      <th>text</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>words_lemmatized</th>\n",
       "      <th>word_count_cleaned_no_digits</th>\n",
       "      <th>top_5_words_tfidf</th>\n",
       "      <th>doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1821</td>\n",
       "      <td>33</td>\n",
       "      <td>DEATH</td>\n",
       "      <td>33 charles yates was indicted for burglariousl...</td>\n",
       "      <td>2728</td>\n",
       "      <td>2624</td>\n",
       "      <td>[33, charles, yates, indicted, burglariously, ...</td>\n",
       "      <td>512</td>\n",
       "      <td>214</td>\n",
       "      <td>[charle, yate, indict, burglariously, break, e...</td>\n",
       "      <td>210</td>\n",
       "      <td>[(passage, 0.19175750857023086), (door, 0.2442...</td>\n",
       "      <td>[0.5797637, -0.78482175, 1.4409305, -1.0716355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1814</td>\n",
       "      <td>28</td>\n",
       "      <td>None</td>\n",
       "      <td>99 hannah housden and sarah housden were indic...</td>\n",
       "      <td>1310</td>\n",
       "      <td>1253</td>\n",
       "      <td>[99, hannah, housden, sarah, housden, indicted...</td>\n",
       "      <td>256</td>\n",
       "      <td>127</td>\n",
       "      <td>[hannah, housden, sarah, housden, indict, felo...</td>\n",
       "      <td>119</td>\n",
       "      <td>[(luke, 0.21885024189327798), (shoe, 0.2222069...</td>\n",
       "      <td>[1.8046134, 1.0367785, 2.466086, 1.925455, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1814</td>\n",
       "      <td>29</td>\n",
       "      <td>Transported for Seven Years</td>\n",
       "      <td>100 joseph martin was indicted for feloniously...</td>\n",
       "      <td>1652</td>\n",
       "      <td>1591</td>\n",
       "      <td>[100, joseph, martin, indicted, feloniously, s...</td>\n",
       "      <td>324</td>\n",
       "      <td>144</td>\n",
       "      <td>[joseph, martin, indict, feloniously, steal, j...</td>\n",
       "      <td>139</td>\n",
       "      <td>[(horse, 0.18510737089369123), (man, 0.1977650...</td>\n",
       "      <td>[1.103122, -1.730811, 2.020693, 0.17772216, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1796</td>\n",
       "      <td>10</td>\n",
       "      <td>Transported for seven years</td>\n",
       "      <td>580 william moss was indicted for feloniously ...</td>\n",
       "      <td>2358</td>\n",
       "      <td>2238</td>\n",
       "      <td>[580, william, moss, indicted, feloniously, st...</td>\n",
       "      <td>428</td>\n",
       "      <td>186</td>\n",
       "      <td>[william, moss, indict, feloniously, steal, oc...</td>\n",
       "      <td>174</td>\n",
       "      <td>[(snuffbox, 0.1922942721958252), (apprentice, ...</td>\n",
       "      <td>[0.32787248, -0.4707733, -0.44840387, 0.873489...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1821</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>13 william wooley was indicted for burglarious...</td>\n",
       "      <td>8339</td>\n",
       "      <td>8014</td>\n",
       "      <td>[13, william, wooley, indicted, burglariously,...</td>\n",
       "      <td>1678</td>\n",
       "      <td>621</td>\n",
       "      <td>[william, wooley, indict, burglariously, break...</td>\n",
       "      <td>613</td>\n",
       "      <td>[(ward, 0.1881756870348805), (run, 0.216856796...</td>\n",
       "      <td>[-1.4594783, -0.38962758, -0.22853056, -3.2740...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  trial_number                   punishment  \\\n",
       "700  1821            33                        DEATH   \n",
       "580  1814            28                         None   \n",
       "581  1814            29  Transported for Seven Years   \n",
       "419  1796            10  Transported for seven years   \n",
       "680  1821            13                         None   \n",
       "\n",
       "                                                  text  dirty_len  clean_len  \\\n",
       "700  33 charles yates was indicted for burglariousl...       2728       2624   \n",
       "580  99 hannah housden and sarah housden were indic...       1310       1253   \n",
       "581  100 joseph martin was indicted for feloniously...       1652       1591   \n",
       "419  580 william moss was indicted for feloniously ...       2358       2238   \n",
       "680  13 william wooley was indicted for burglarious...       8339       8014   \n",
       "\n",
       "                                                 words  word_count  \\\n",
       "700  [33, charles, yates, indicted, burglariously, ...         512   \n",
       "580  [99, hannah, housden, sarah, housden, indicted...         256   \n",
       "581  [100, joseph, martin, indicted, feloniously, s...         324   \n",
       "419  [580, william, moss, indicted, feloniously, st...         428   \n",
       "680  [13, william, wooley, indicted, burglariously,...        1678   \n",
       "\n",
       "     word_count_cleaned                                   words_lemmatized  \\\n",
       "700                 214  [charle, yate, indict, burglariously, break, e...   \n",
       "580                 127  [hannah, housden, sarah, housden, indict, felo...   \n",
       "581                 144  [joseph, martin, indict, feloniously, steal, j...   \n",
       "419                 186  [william, moss, indict, feloniously, steal, oc...   \n",
       "680                 621  [william, wooley, indict, burglariously, break...   \n",
       "\n",
       "     word_count_cleaned_no_digits  \\\n",
       "700                           210   \n",
       "580                           119   \n",
       "581                           139   \n",
       "419                           174   \n",
       "680                           613   \n",
       "\n",
       "                                     top_5_words_tfidf  \\\n",
       "700  [(passage, 0.19175750857023086), (door, 0.2442...   \n",
       "580  [(luke, 0.21885024189327798), (shoe, 0.2222069...   \n",
       "581  [(horse, 0.18510737089369123), (man, 0.1977650...   \n",
       "419  [(snuffbox, 0.1922942721958252), (apprentice, ...   \n",
       "680  [(ward, 0.1881756870348805), (run, 0.216856796...   \n",
       "\n",
       "                                               doc2vec  \n",
       "700  [0.5797637, -0.78482175, 1.4409305, -1.0716355...  \n",
       "580  [1.8046134, 1.0367785, 2.466086, 1.925455, -0....  \n",
       "581  [1.103122, -1.730811, 2.020693, 0.17772216, -0...  \n",
       "419  [0.32787248, -0.4707733, -0.44840387, 0.873489...  \n",
       "680  [-1.4594783, -0.38962758, -0.22853056, -3.2740...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's assign these vectors to our dataframe\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "\n",
    "df[\"doc2vec\"] = df.index.map(lambda x: d2v_model.dv[x])\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# let's see what we have\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have a 50 length vector for each document that we can use for comparison and other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:00:00.577447\n"
     ]
    }
   ],
   "source": [
    "# finally let's save our dataframe to pickle file again\n",
    "\n",
    "# we will use to_pickle method\n",
    "\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "pickle_file = Path(\"old_bailey_sample_1720_1913_cleaned_embeddings.pkl\")\n",
    "\n",
    "df.to_pickle(pickle_file, compression=\"zip\")\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find the closesq document to our first document\n",
    "# we will use cosine similarity\n",
    "# we will use sklearn cosine_similarity function\n",
    "# we will use our doc2vec embeddings\n",
    "\n",
    "# let's get embeddings for first document\n",
    "first_doc_d2v = df.doc2vec.iloc[0]\n",
    "# let's see what we have\n",
    "first_doc_d2v\n",
    "\n",
    "# let's get embeddings for all documents\n",
    "all_docs_d2v = df.doc2vec.tolist()\n",
    "\n",
    "# now simply use cosine_similarity function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# let's see what we have\n",
    "cosine_similarity([first_doc_d2v], all_docs_d2v)\n",
    "# find index of most similar document\n",
    "np.argmax(cosine_similarity([first_doc_d2v], all_docs_d2v))\n",
    "# unsurprisingly it is the first document - which is the same document\n",
    "# somewhat surprisingly sometimes it is not the same document - due to the way doc2vec works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-07-25 02:05:54.100676\n",
      "Time elapsed: 0:00:00.001998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99999994, 0.45778802, 0.586551  , ..., 0.49315554, 0.33341596,\n",
       "        0.40257853]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so now let's find top 5 most similar documents to our first document\n",
    "# we will use cosine similarity\n",
    "# we will use sklearn cosine_similarity function\n",
    "# we will use our doc2vec embeddings\n",
    "\n",
    "# we already have our first document embeddings\n",
    "# we already have our all documents embeddings\n",
    "\n",
    "# let's get cosine similarity for all documents\n",
    "# start of timer\n",
    "start = datetime.now()\n",
    "print(f\"Start time: {start}\")\n",
    "cosine_similarities = cosine_similarity([first_doc_d2v], all_docs_d2v)\n",
    "print(f\"Time elapsed: {datetime.now() - start}\")\n",
    "# let's see what we have\n",
    "cosine_similarities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>trial_number</th>\n",
       "      <th>punishment</th>\n",
       "      <th>text</th>\n",
       "      <th>dirty_len</th>\n",
       "      <th>clean_len</th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleaned</th>\n",
       "      <th>words_lemmatized</th>\n",
       "      <th>word_count_cleaned_no_digits</th>\n",
       "      <th>top_5_words_tfidf</th>\n",
       "      <th>doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1720</td>\n",
       "      <td>31</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>elizabeth evans of st martins in the fields wa...</td>\n",
       "      <td>548</td>\n",
       "      <td>531</td>\n",
       "      <td>[elizabeth, evans, st, martins, fields, indict...</td>\n",
       "      <td>99</td>\n",
       "      <td>49</td>\n",
       "      <td>[elizabeth, evans, st, martin, field, indict, ...</td>\n",
       "      <td>46</td>\n",
       "      <td>[(good, 0.25535662554576005), (sling, 0.255521...</td>\n",
       "      <td>[0.58074266, -0.23915628, 0.6932438, 0.1311166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1754</td>\n",
       "      <td>25</td>\n",
       "      <td>[Transportation. See summary.]</td>\n",
       "      <td>110 m elizabeth hore widow was indicted for st...</td>\n",
       "      <td>846</td>\n",
       "      <td>804</td>\n",
       "      <td>[110, m, elizabeth, hore, widow, indicted, ste...</td>\n",
       "      <td>145</td>\n",
       "      <td>80</td>\n",
       "      <td>[m, elizabeth, hore, widow, indict, steal, sil...</td>\n",
       "      <td>74</td>\n",
       "      <td>[(handkerchief, 0.24678087995418604), (pair, 0...</td>\n",
       "      <td>[0.5283339, -0.7592295, 1.0327351, 0.62489116,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1742</td>\n",
       "      <td>18</td>\n",
       "      <td>[Whipping. See summary.]</td>\n",
       "      <td>20 william bristow was indicted for stealing 2...</td>\n",
       "      <td>160</td>\n",
       "      <td>149</td>\n",
       "      <td>[20, william, bristow, indicted, stealing, 2, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>[william, bristow, indict, steal, pound, butte...</td>\n",
       "      <td>16</td>\n",
       "      <td>[(williams, 0.2751791772613587), (butter, 0.35...</td>\n",
       "      <td>[-0.18151693, -0.22353244, 0.17316304, 0.12753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1731</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>sarah davis of st brides was indicted for felo...</td>\n",
       "      <td>249</td>\n",
       "      <td>240</td>\n",
       "      <td>[sarah, davis, st, brides, indicted, felonious...</td>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>[sarah, davis, st, bride, indict, feloniously,...</td>\n",
       "      <td>21</td>\n",
       "      <td>[(chair, 0.2540785345847826), (cane, 0.3206741...</td>\n",
       "      <td>[-0.10121408, -0.4496861, 0.35704604, -0.12270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1720</td>\n",
       "      <td>1</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>of st leonard eastcheap was indicted for felon...</td>\n",
       "      <td>705</td>\n",
       "      <td>684</td>\n",
       "      <td>[st, leonard, eastcheap, indicted, feloniously...</td>\n",
       "      <td>129</td>\n",
       "      <td>66</td>\n",
       "      <td>[st, leonard, eastcheap, indict, feloniously, ...</td>\n",
       "      <td>60</td>\n",
       "      <td>[(confest, 0.1972391174872452), (depose, 0.215...</td>\n",
       "      <td>[0.5782519, -0.7623888, 0.6419972, -0.01352496...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  trial_number                      punishment  \\\n",
       "30   1720            31                  Transportation   \n",
       "264  1754            25  [Transportation. See summary.]   \n",
       "170  1742            18        [Whipping. See summary.]   \n",
       "99   1731            25                            None   \n",
       "0    1720             1                  Transportation   \n",
       "\n",
       "                                                  text  dirty_len  clean_len  \\\n",
       "30   elizabeth evans of st martins in the fields wa...        548        531   \n",
       "264  110 m elizabeth hore widow was indicted for st...        846        804   \n",
       "170  20 william bristow was indicted for stealing 2...        160        149   \n",
       "99   sarah davis of st brides was indicted for felo...        249        240   \n",
       "0    of st leonard eastcheap was indicted for felon...        705        684   \n",
       "\n",
       "                                                 words  word_count  \\\n",
       "30   [elizabeth, evans, st, martins, fields, indict...          99   \n",
       "264  [110, m, elizabeth, hore, widow, indicted, ste...         145   \n",
       "170  [20, william, bristow, indicted, stealing, 2, ...          27   \n",
       "99   [sarah, davis, st, brides, indicted, felonious...          44   \n",
       "0    [st, leonard, eastcheap, indicted, feloniously...         129   \n",
       "\n",
       "     word_count_cleaned                                   words_lemmatized  \\\n",
       "30                   49  [elizabeth, evans, st, martin, field, indict, ...   \n",
       "264                  80  [m, elizabeth, hore, widow, indict, steal, sil...   \n",
       "170                  21  [william, bristow, indict, steal, pound, butte...   \n",
       "99                   22  [sarah, davis, st, bride, indict, feloniously,...   \n",
       "0                    66  [st, leonard, eastcheap, indict, feloniously, ...   \n",
       "\n",
       "     word_count_cleaned_no_digits  \\\n",
       "30                             46   \n",
       "264                            74   \n",
       "170                            16   \n",
       "99                             21   \n",
       "0                              60   \n",
       "\n",
       "                                     top_5_words_tfidf  \\\n",
       "30   [(good, 0.25535662554576005), (sling, 0.255521...   \n",
       "264  [(handkerchief, 0.24678087995418604), (pair, 0...   \n",
       "170  [(williams, 0.2751791772613587), (butter, 0.35...   \n",
       "99   [(chair, 0.2540785345847826), (cane, 0.3206741...   \n",
       "0    [(confest, 0.1972391174872452), (depose, 0.215...   \n",
       "\n",
       "                                               doc2vec  \n",
       "30   [0.58074266, -0.23915628, 0.6932438, 0.1311166...  \n",
       "264  [0.5283339, -0.7592295, 1.0327351, 0.62489116,...  \n",
       "170  [-0.18151693, -0.22353244, 0.17316304, 0.12753...  \n",
       "99   [-0.10121408, -0.4496861, 0.35704604, -0.12270...  \n",
       "0    [0.5782519, -0.7623888, 0.6419972, -0.01352496...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want indexes of top 5 most similar documents\n",
    "# we can use argsort\n",
    "# let's see what we have\n",
    "top_5_similar = np.argsort(cosine_similarities)[0][-5:]\n",
    "# let's see what we have\n",
    "top_5_similar\n",
    "# good news is that 0 is the first document so it makes sense for it to be most similar to itself\n",
    "# let's print the rest of the documents\n",
    "df.iloc[top_5_similar]\n",
    "\n",
    "# we still have to make some decisions about how to use these embeddings\n",
    "# there will be need for human judgement on how to use them\n",
    "# at a brief glance it looks like we have some documents that some similarities lie in gender of the defendant\n",
    "# also these documents seem early in our corpus - which make sense as language changes over time\n",
    "\n",
    "# there are many more things we can do with embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further discussion\n",
    "\n",
    "There are other ways to build embeddings, such as GloVe and FastText. We will not cover them here, but they are worth looking into.\n",
    "\n",
    "There are also below word embeddings which do their own tokenization.\n",
    "\n",
    "for example Byte Level BPE (BBPE) and WordPiece (WP) tokenization.\n",
    "\n",
    "## References\n",
    "\n",
    "https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "Official gensim docs:\n",
    "https://radimrehurek.com/gensim/auto_examples/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks for tomorrow\n",
    "\n",
    "What type of dataset do you want to use?\n",
    "What type of embeddings do you want to build? What type of model do you want to use? \n",
    "What type of evaluation do you want to use?\n",
    "\n",
    "Tomorrow in the first part we will do some topic modelling using LDA - Latent Dirichlet Allocation and extra visualisations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
