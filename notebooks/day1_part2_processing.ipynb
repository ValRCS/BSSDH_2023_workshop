{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Part 2 - Processing\n",
    "\n",
    "Text processing involves tokenization, stemming, lemmatization, and other techniques to transform text into a more digestible format for futher analysis.\n",
    "\n",
    "We might want to normalize text by removing punctuation, converting to lowercase, and removing stop words. We might also want to stem or lemmatize words to reduce them to their root form."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
