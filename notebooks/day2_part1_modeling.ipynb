{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models \n",
    "\n",
    "Now that we've created some embeddings, we can use them to build models. We'll start with a k-means clustering model. We'll use the embeddings to cluster the data into 10 clusters. We'll then use the cluster assignments to create a new feature for each data point. We'll then use this new feature to train a logistic regression model to predict the target variable.\n",
    "\n",
    "Time allowing we will build a Latent Dirichlet Allocation (LDA) model. LDA is a topic modeling technique that is often used to discover topics in text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Clustering is an unsupervised learning technique that groups data points into clusters based on their similarity. The similarity is measured using a distance metric. The most common distance metric is Euclidean distance. The goal of clustering is to group data points that are similar to each other into the same cluster.\n",
    "\n",
    "### Uses of clustering\n",
    "\n",
    "Clustering leaves room for interpretation. There is no right or wrong answer. This makes clustering useful for exploratory data analysis. Clustering can help us understand the structure of the data. It can help us identify outliers. It can help us identify groups of similar data points. It can help us identify groups of dissimilar data points. It can help us identify groups of data points that are similar to each other but dissimilar to data points in other groups.\n",
    "\n",
    "As far as text analysis goes, clustering can help us identify groups of similar documents. Then we as human curators can label the clusters. This can help us understand the structure of the corpus. It can help us identify outliers. It can help us identify groups of similar documents. It can help us identify groups of dissimilar documents. It can help us identify groups of documents that are similar to each other but dissimilar to documents in other groups.\n",
    "\n",
    "### k-means clustering\n",
    "\n",
    "The most common clustering algorithm is k-means clustering. The algorithm works as follows:\n",
    "\n",
    "1. Randomly initialize k cluster centroids\n",
    "2. Assign each data point to the cluster whose centroid is closest to it\n",
    "3. Recompute the cluster centroids\n",
    "4. Repeat steps 2 and 3 until the cluster assignments stop changing\n",
    "\n",
    "There are some edge cases that can cause the algorithm to fail to converge. For example, if a cluster ends up with no data points assigned to it, then the centroid of that cluster will be undefined. In this case, the algorithm will fail to converge. To avoid this, we can use a modified version of the algorithm that allows for empty clusters. This modified version of the algorithm is called k-means++.\n",
    "\n",
    "More about k-means: https://en.wikipedia.org/wiki/K-means_clustering\n",
    "\n",
    "### k-means in practice\n",
    "\n",
    "We do not have to implement the k-means algorithm ourselves. We can use the implementation provided by scikit-learn. The scikit-learn implementation of k-means uses the k-means++ initialization method by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building models from our embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
